# -*- coding: utf-8 -*-
"""배포_Image_Preprocessing_colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eUWx6RyBAS3EokrAuQxrjFo4aNX2R4am

# **About OpenCV**
* Officially launched in 1999, OpenCV (Open Source Computer Vision) from an Intel initiative.
* OpenCV’s core is written in C++. In python we are simply using a wrapper that executes C++ code inside of python.
* First major release 1.0 was in 2006, second in 2009, third in 2015 and 4th in 2018. with OpenCV 4.0 Beta.
* It is an Open source library containing over 2500 optimized algorithms.
* It is EXTREMELY useful for almost all computer vision applications and is supported on Windows, Linux, MacOS, Android, iOS with bindings to Python, Java and Matlab.
* https://docs.opencv.org/4.x/index.html
- https://docs.opencv.org/4.5.4/d7/da8/tutorial_table_of_content_imgproc.html
- https://docs.opencv.org/4.x/d9/df8/tutorial_root.html
"""

!pip install pydicom -q

"""# 파일 다운로드

"""

import os
import zipfile
import urllib.request

# imgproc 파일 다운로드 및 압축해제
zip_url = "https://github.com/bykim9988/imgproc/archive/refs/heads/master.zip"
zip_file = "imgproc.zip"
IMG_DIR = "imgproc-master/"

# 다운로드
urllib.request.urlretrieve(zip_url, zip_file)

# 압축 해제
with zipfile.ZipFile(zip_file, 'r') as zip_ref:
    zip_ref.extractall()

# 결과 확인
print(f"{IMG_DIR} 디렉토리에 압축이 해제되었습니다.")

if os.path.exists(zip_file):
    os.remove(zip_file)
    print(f"{zip_file} 삭제 완료")

import numpy as np
import cv2
import matplotlib.pyplot as plt

img_list = ['chest_01.png', 'chest_02.png','chest_03.png']
for file in img_list:
    file_path = IMG_DIR + file
    image1 = plt.imread(file_path)
    print(f"FILE........: {file_path}")
    print(f"Original....: {image1.min()}, {image1.max() }")
    image2 = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
    print(f"GrayScaled..: {image2.min()}, {image2.max() }\n")

"""# 1. 그레이 영상과 컬러영상"""

image1 =  cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)

image2 = cv2.imread( )


plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.title("Gray image")
plt.imshow(image1, cmap='gray')

plt.subplot(1, 2, 2)
plt.title("Color image")
plt.imshow(image2)
plt.show()

"""### color 영상을 R, G, B 각 영상으로 분할해 보기"""

image2 = cv2.imread(  )


plt.figure(figsize=(20, 10))
plt.subplot(2, 4, 1)
plt.title("Original image")
plt.imshow(image2)
plt.subplot(2, 4, 2)
plt.title("Red")
plt.imshow(image2[:,:,0], cmap='Reds', vmin=0, vmax=255)
plt.subplot(2, 4, 3)
plt.title("Green")
plt.imshow(image2[:,:,1], cmap='Greens', vmin=0, vmax=255)
plt.subplot(2, 4, 4)
plt.title("Blue")
plt.imshow(image2[:,:,2], cmap='Blues', vmin=0, vmax=255)

plt.show()

"""# # 영상 정규화"""

image1 = cv2.imread( )
scaled =

plt.figure(figsize=(10, 10))
plt.subplot(2, 2, 1)
plt.title("Original Image"+": range %d~%d"%(image1.min(), image1.max()))
plt.imshow(image1, cmap='gray', vmin=0, vmax=255)
plt.subplot(2, 2, 2)
plt.title("MinMax Scaled"+": range %.2f~%.2f"%(scaled.min(), scaled.max()))
plt.imshow(scaled, cmap='gray', vmin=0.0, vmax=1.0)

plt.show()

"""## ● 데이터 증강을 위한 전처리 도구 ImageDataGenerator
- https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator
- 의료 데이터 증강 참고 논문:
- - 딥러닝 기반 의료 영상 분석을 위한 데이터 증강 기법, 대한 의학 영상학회지, 2020.81(6)
- - https://pmc.ncbi.nlm.nih.gov/articles/PMC9431833/

"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

file_list = ['chest_01.png', 'chest_02.png','chest_03.png']

img_list = []
for file in file_list:
    file_path = IMG_DIR + file
    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)

    img_list.append(img)

x_train = np.array(img_list)
y_train = np.array([0,1,2])

class_names=['X_ray0','X_ray1','X_ray2']


batch_siz=3
generator=ImageDataGenerator(rotation_range= ,
                             width_shift_range= ,
                             height_shift_range= ,
                             shear_range= ,
                             zoom_range= ,
                             horizontal_flip= )
gen=generator.flow(   )

for a in range(10):
    img,label=next(gen)
    plt.figure(figsize=(8, 3))
    plt.suptitle("Generator trial "+str(a+1))
    for i in range(batch_siz):
        plt.subplot(1, batch_siz, i+1)
        plt.imshow(  )
        plt.xticks([]); plt.yticks([]); plt.grid(False)
        plt.title(class_names[int(label[i])])
    plt.show()

"""# 2.히스토그램

- https://docs.opencv.org/4.5.4/d8/dbc/tutorial_histogram_calculation.html

## 2.1 히스토그램 계산
"""

image1 = cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)
image1_hist =

image2 = cv2.imread(IMG_DIR+'chest_02.png',cv2.IMREAD_GRAYSCALE)
image2_hist =

plt.figure(figsize=(10, 10))
plt.subplot(2, 2, 1)
plt.title("Gray image")
plt.imshow(image1, cmap='gray', vmin=0, vmax=255)
plt.subplot(2, 2, 3)
plt.title("Histogram")
plt.bar(range(len(image1_hist)), image1_hist.reshape(-1,))

plt.show()

"""## 2.2 히스토그램 스트레칭과 평활화"""

img = cv2.imread(IMG_DIR+'chest_02.png',cv2.IMREAD_GRAYSCALE)
img_hist =

# 히스토그램 스트레칭
def histogram_stretching(img, new_min=0, new_max=255):
    min_val = np.min(img)
    max_val = np.max(img)
    stretched = ((img - min_val) / (max_val - min_val) * (new_max - new_min) + new_min).astype(np.uint8)
    return stretched

# 히스토그램 이퀄라이제이션
equalized =

# 히스토그램 스트레칭 적용
stretched =

# 결과 시각화
titles = ['Original', 'Stretched', 'Equalized']
images = [img, stretched, equalized]

plt.figure(figsize=(15, 10))
for i in range(3):
    plt.subplot(2, 3, i+1)
    plt.imshow(images[i], cmap='gray' )
    plt.title(titles[i])
    plt.axis('off')

    plt.subplot(2, 3, i+4)
    plt.hist(images[i].flatten(), 256, [0, 256])
    plt.title(titles[i] + ' Histogram')

plt.tight_layout()
plt.show()

"""# 3. Affine Transform

- https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga0203d9ee5fcd28d40dbc4a1ea4451983

## 3.1 평행 이동
"""

src = cv2.imread(IMG_DIR+'chest_06.png',cv2.IMREAD_GRAYSCALE)

dx, dy = eval(input('x축 이동거리, y축이동 거리 : '))

# np.array로 Affine 행렬 생성
aff =

dst =

plt.subplot(1, 2, 1)
plt.title("Original image")
plt.imshow(src, cmap='gray')
plt.subplot(1, 2, 2)
plt.title("Result")
plt.imshow(dst, cmap='gray')
plt.show()

"""## 3.2 Affine Transform: 회전"""

import math


theta = int(input('회전 각도: '))
rad = theta * math.pi / 180 # 각도 설정

# 영상의 중심을 기준으로 회전


# 이미지의 중심 좌표 계산
(h, w) = src.shape[:2]
center = (w // 2, h // 2)
# 스케일 설정 (1.0은 원본 크기 유지)
scale = 1.0

# 회전 행렬 생성
aff =
dst =

"""## 3.3 Affine Transform: 확대, 축소

### ▶ 확대 후: 물체가 중앙에 위치하도록 상,하,좌,우 shift 필요
- imageGenerator에서는 확대 scale과 shift 같이..

### ▶ 축소 후: 물체가 중앙에 위치하면서 원영상 크기로 조정 필요
"""

src = cv2.imread(IMG_DIR+'678_left.png')
src = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)
height, width, channel = src.shape

alpha = 1.2   # 확대

dst =

s_x =
s_y =

print(f'복사 시작 위치: ({s_y:d}, {s_x:d}), 확대 후(폭: {s_w}, 높이: {s_h})')
dst1 = np.zeros_like(src)


beta = 0.9    # 축소
s_w =
s_h =

dst2 = np.zeros_like(src)
s_y =
s_x =
dst2
print(f'복사 시작 위치: ({s_y:d}, {s_x:d}), 축소 후(폭: {s_w}, 높이: {s_h})')


plt.figure(figsize=(10, 5))
plt.subplot(1, 3, 1)
plt.title("Original image")
plt.imshow(src)

plt.subplot(1, 3, 2)
plt.title("Enlarged")
plt.imshow(dst1)

plt.subplot(1, 3, 3)
plt.title("Reduced: Centered")
plt.imshow(dst2)
plt.show()

image = cv2.imread(IMG_DIR+'butterfly.jpg')
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)


plt.figure(figsize=(10, 10))

plt.subplot(2, 2, 1)
plt.title("Original")
plt.imshow(image)

# 3/4 배로
image_scaled = cv2.resize(  )

plt.subplot(2, 2, 2)
plt.title(f"Reduced:{image_scaled.shape[1]:d} X {image_scaled.shape[0]:d}")
plt.imshow(image_scaled)

# 2배로 크게
img_scaled = cv2.resize(  )

plt.subplot(2, 2, 3)
plt.title(f"Enlarged:{img_scaled.shape[1]:d} X {img_scaled.shape[0]:d}")
plt.imshow(img_scaled)

# 224x224로 크기 변환
img_scaled = cv2.resize(  )

plt.subplot(2, 2, 4)
plt.title(f"{img_scaled.shape[1]:d} X {img_scaled.shape[0]:d} resized")
plt.imshow(img_scaled)
plt.show()

"""# 3.3. 대칭(flip)"""

src = cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)
dst1 =
dst2 =
dst3 =

plt.figure(figsize=(8, 8))
plt.subplot(2, 2, 1)
plt.title("Original image")
plt.imshow(src, cmap='gray', vmin=0, vmax=255)

plt.subplot(2, 2, 2)
plt.title("Vertical flip")
plt.imshow(dst1, cmap='gray', vmin=0, vmax=255)

plt.subplot(2, 2, 3)
plt.title("Horizontal flip")
plt.imshow(dst2, cmap='gray', vmin=0, vmax=255)

plt.subplot(2, 2, 4)
plt.title("Antipodal mapping")
plt.imshow(dst3, cmap='gray', vmin=0, vmax=255)
plt.show()

"""# 4. 푸리에 변환"""

import numpy as np
import matplotlib.pyplot as plt

# 샘플링 파라미터
fs = 500          # 샘플링 주파수 (Hz)
T = 2             # 신호 길이 (초)
t = np.linspace(0, T, fs * T, endpoint=False)

# 주파수 성분별 신호 생성
sig_2hz =   np.sin(2 * np.pi * 2 * t)
sig_3hz =   np.sin(2 * np.pi * 3 * t)       # dominant
sig_7hz =   np.sin(2 * np.pi * 7 * t)
sig_10hz =   np.sin(2 * np.pi * 10 * t)
sig_20hz =   np.sin(2 * np.pi * 20 * t)

# ▶ 누적 합성 신호
sum1 = sig_2hz
sum2 = sum1 + sig_3hz
sum3 = sum2 + sig_7hz
sum4 = sum3 + sig_10hz
sum5 = sum4 + sig_20hz  # 최종 신호

# ▶ 시각화
plt.figure(figsize=(10, 10))
plt.subplot(511); plt.plot(t, sum1); plt.title("2Hz")
plt.subplot(512); plt.plot(t, sum2); plt.title("2Hz + 3Hz")
plt.subplot(513); plt.plot(t, sum3); plt.title("2Hz + 3Hz + 7Hz")
plt.subplot(514); plt.plot(t, sum4); plt.title("2Hz + 3Hz + 7Hz + 10Hz")
plt.subplot(515); plt.plot(t, sum5); plt.title("최종 합성 신호")
plt.tight_layout(); plt.show()

from scipy.fft import fft, fftfreq, ifft

# 합성 신호
composite_signal = sig_2hz + sig_3hz + sig_7hz + sig_10hz + sig_20hz

# 푸리에 변환
N = len(composite_signal)
yf = fft(composite_signal)
xf = fftfreq(N, 1/fs)

# 진폭 계산 및 정렬
amplitude = np.abs(yf) / N
pos_mask = (xf >= 0)
xf_pos = xf[pos_mask]
amp_pos = amplitude[pos_mask]
sorted_indices = np.argsort(amp_pos)[::-1]  # 진폭 내림차순

print("주파수 성분 정렬:")
for i in range(5):
    freq = xf_pos[sorted_indices[i]]
    amp = amp_pos[sorted_indices[i]]
    print(f"{i+1}) {freq:.2f} Hz: amplitude={amp:.3f}")

# 시각화
plt.figure(figsize=(12, 4)); plt.plot(xf_pos, amp_pos)
plt.title("합성 신호의 주파수 스펙트럼 (FFT)"); plt.xlabel("Frequency (Hz)")
plt.ylabel("Amplitude"); plt.grid(True)
plt.xlim(0, 30)  # 분석 범위 제한
plt.tight_layout()
plt.show()

a = np.repeat([0, 255], 10)
gray = np.tile(a, (100, 10))

f_img = np.fft. (gray)
fimg =  np.fft. (f_img)

mag = 20*np.log(np.abs(fimg)+1)
i_fft = np.fft. (f_img)
i_fft = np. (i_fft)


plt.figure( figsize = (20, 10))
plt.subplot(131)
plt.imshow(gray, cmap = 'gray')
plt.subplot(132)
plt.imshow(mag, cmap = 'gray')
plt.subplot(133)
plt.imshow(i_fft, cmap = 'gray')
plt.show()

"""## OpenCV 푸리에 변환
- dft:  https://docs.opencv.org/3.4/d8/d01/tutorial_discrete_fourier_transform.html
- idft: https://docs.opencv.org/3.4/d2/de8/group__core__array.html#gaa708aa2d2e57a508f968eb0f69aa5ff1
"""

img = cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)
dft = cv2. (np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)
dft_shift = np.fft. (dft)

mag = 20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]) + 1)

rows, cols = img.shape
crow,ccol = rows//2 , cols//2

# Low-pass Filtering
mask = np. ((rows,cols, 2),np.uint8)
mask[crow-50:crow+50, ccol-50:ccol+50] =

f_shift = dft_shift
idft_shift = np.fft.fftshift( f_shift )
i_fft =  cv2.idft( idft_shift)
i_fft = cv2.magnitude(i_fft[:,:,0], i_fft[:,:,1])

plt.figure( figsize = (20, 5) )
plt.subplot(141),plt.imshow(img, cmap = 'gray')
plt.title('Input Image'); plt.xticks([]); plt.yticks([])
plt.subplot(142),plt.imshow(mag, cmap = 'gray')
plt.title('Magnitude Spectrum'); plt.xticks([]); plt.yticks([])
plt.subplot(143),plt.imshow( mask[:,:,0], cmap = 'gray')
plt.title('Low-pass Filter'); plt.xticks([]); plt.yticks([])
plt.subplot(144),plt.imshow(i_fft, cmap = 'gray')
plt.title('Low-pass Filtered'); plt.xticks([]); plt.yticks([])
plt.show()

img = cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)

# 이미지의 중심 좌표 계산
(h, w) = img.shape[:2]
center = (w // 2, h // 2)
# 회전 행렬 생성
aff = cv2.getRotationMatrix2D(center, 15, 1.0)
dst = cv2.warpAffine(src, aff, (w, h))

img = cv2.imread(IMG_DIR+'lena.jpg',cv2.IMREAD_GRAYSCALE)
d
# High-pass Filtering
w = 60
mask = np. ((rows,cols, 2),np.uint8)
mask[crow-w//2:crow+w//2, ccol-w//2:ccol+w//2] =

"""# 5. Convolution
- https://en.wikipedia.org/wiki/Convolution
- https://en.wikipedia.org/wiki/Kernel_(image_processing)

## 5.1 Convolution: Blurring
"""

image1 = cv2.imread(IMG_DIR+'pic2.png')
src = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)
ksize=7
dst1=

ksize=7
dst2 =

plt.figure(figsize=(10, 5))
plt.subplot(1, 3, 1);plt.title("Original image");plt.imshow(src )
plt.subplot(1, 3, 2);plt.title("Blurred");plt.imshow(dst1)
plt.subplot(1, 3, 3);plt.title("Gaussian blurred");plt.imshow(dst2)
plt.show()

"""## 5.2 Convolution: Sharpening
#### cv2.addWeighted
- https://docs.opencv.org/3.4/d2/de8/group__core__array.html#gafafb2513349db3bcff51f54ee5592a19

#### cv2.filter2D
- https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#ga27c049795ce870216ddfb366086b5a04
"""

image =


kernel_sharpening = np.array([[-1,-1,-1],
                              [-1,9,-1],
                              [-1,-1,-1]])

sharpened = cv2.filter2D(image, -1, kernel_sharpening)


laplacian_1 = np.array([[0, -1, 0],
                      [-1, 5, -1],
                      [0, -1, 0]])
laplacian_2 = np.array([[1, -2, 1],
                      [-2, 5, -2],
                      [1, -2, 1]])
laplacian_1 = cv2.convertScaleAbs(cv2.filter2D(image, -1, laplacian_1))

laplacian_2 = cv2.convertScaleAbs(cv2.filter2D(image, -1, laplacian_2))

laplacian_sharpened = cv2.addWeighted(laplacian_1, 0.5, laplacian_2, 0.5, 0)

"""## 5.3 Convolution: 에지(모서리) 추출

#### edge detector Laplacian
- https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#gad78703e4c8fe703d479c1860d76429e6

#### edge detector Sobel
- https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#gacea54f142e81b6758cb6f375ce782c8d

#### edge detector Canny
- https://docs.opencv.org/4.x/da/d5c/tutorial_canny_detector.html
"""

gray = cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)

kernel_size = 5  # 7 --> 5로
sobelx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, kernel_size) # Sobel_x
   # --> CV_8U는 underflow, overflow가 있으니, 와 32F 를 사용하는 것이 안전하다.
sobely = cv2.Sobel(gray, cv2.CV_32F, 0, 1, kernel_size) # Sobel_y
sobel = cv2.addWeighted( cv2.convertScaleAbs( sobelx ), 0.5, cv2.convertScaleAbs(sobely), 0.5, 0)

laplacian = cv2.Laplacian(gray, cv2.CV_8U, ksize=kernel_size)
canny = cv2.Canny(gray, 30, 50, L2gradient=True)
canny2 = cv2.Canny(gray, 20, 50, L2gradient=True)

ksize=5
blur= cv2.GaussianBlur(gray, (ksize, ksize), 2)
canny3 = cv2.Canny(blur, 40, 50, L2gradient=True)

plt.figure(figsize=(20, 16))
plt.subplot(2, 3, 1)
plt.title("Original image")
plt.imshow(gray, cmap='gray', vmin=0, vmax=255)

plt.subplot(2, 3, 2)
plt.title("Sobel")
plt.imshow(sobel, cmap='gray')

plt.subplot(2, 3, 3)
plt.title("Laplacian")
plt.imshow(laplacian, cmap='gray')

plt.subplot(2, 3, 4)
plt.title("Canny(30-50)")
plt.imshow(canny, cmap='gray')

plt.subplot(2, 3, 5)
plt.title("Canny(20-50)")
plt.imshow(canny2, cmap='gray')

plt.subplot(2, 3, 6)
plt.title("Blurring+Canny(40-50)")
plt.imshow(canny3, cmap='gray')
plt.show()

image1 = cv2.imread(IMG_DIR+'thermal.jpg')
gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)

kernel_size = 5
sobel = cv2.Sobel(gray, cv2.CV_8U, 1, 0, kernel_size)
laplacian = cv2.Laplacian(gray, cv2.CV_8U, ksize=kernel_size)
canny = cv2.Canny(gray, 100, 180)

plt.figure(figsize=(20, 5))
plt.subplot(1, 4, 1)
plt.title("Original")
plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB) )

plt.subplot(1, 4, 2)
plt.title("Gray image")
plt.imshow(gray, cmap='gray')


plt.subplot(1, 4, 3)
plt.title("Laplacian")
plt.imshow(laplacian, cmap='gray')

plt.subplot(1, 4, 4)
plt.title("Canny")
plt.imshow(canny, cmap='gray')
plt.show()

"""## 5.4. 팽창(Dilation), 침식(Erosion), Opening and Closing
- https://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html
"""

image = cv2.imread(IMG_DIR+'LinuxLogo.jpg')
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

#image = cv2.imread(IMG_DIR+'lena.jpg', cv2.IMREAD_GRAYSCALE)


plt.figure(figsize=(10,10))
plt.subplot(3, 2, 1)
plt.title("Original")
plt.imshow(image)

# Let's define our kernel size
kernel = np.ones((5,5), np.uint8)

# Now we erode
erosion = cv2.erode(image, kernel, iterations = 1)
plt.subplot(3, 2, 2)
plt.title("Erosion")
plt.imshow(erosion)

dilation = cv2.dilate(image, kernel, iterations = 1)
plt.subplot(3, 2, 3)
plt.title("Dilation")
plt.imshow(dilation)

# Opening - Good for removing noise
opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)
plt.subplot(3, 2, 4)
plt.title("Opening")
plt.imshow(opening)

# Closing - Good for removing noise
closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)
plt.subplot(3, 2, 5)
plt.title("Closing")
plt.imshow(closing)
plt.show()

!pip install pydicom

from pydicom import dcmread
ds= dcmread(IMG_DIR + '00ac73cfc372.dcm' )
image = ds.pixel_array.copy()


rescaled_image = image * ds.RescaleSlope + ds.RescaleIntercept
plt.figure(figsize=(5,5))
plt.imshow(rescaled_image, cmap="gray")
plt.grid(False)
plt.title("Rescaled")
plt.show()

plt.figure(figsize=(12, 12))
plt.subplot(3, 3, 1)
plt.title("Original")
plt.imshow(rescaled_image, cmap='gray')

# Let's define our kernel size


# Now we erode
erosion =
plt.subplot(3, 3, 2)
plt.title("Erosion")
plt.imshow(erosion, cmap='gray')

dilation =
plt.subplot(3, 3, 3)
plt.title("Dilation")
plt.imshow(dilation, cmap='gray')

# Opening - Good for removing noise
dst1 =
dst1 =
plt.subplot(3, 3, 5)
plt.title("Opening")
plt.imshow(dst1, cmap='gray')

# Closing - Good for removing noise
dst2 = cv2.morphologyEx(rescaled_image, cv2.MORPH_CLOSE, kernel)
plt.subplot(3, 3, 6)
plt.title("Closing")
plt.imshow(dst2, cmap='gray')

plt.subplot(3, 3, 4)
plt.title("dst3:Original - Opening")
dst3 =
plt.imshow(dst3, cmap='gray')

plt.subplot(3, 3, 7)
plt.title("dst4: rescaled - dst3")
dst4 =
plt.imshow(dst4, cmap='gray')

plt.subplot(3, 3, 8)
th,binary1 =
plt.title(f"segmentated by dst4: thr={th:.2f}")
plt.imshow(binary1, cmap='gray')

plt.subplot(3, 3, 9)
th,binary2 =
plt.title(f"segmentated by rescaled_image: thr={th:.2f}")
plt.imshow(binary2, cmap='gray')

plt.show()

"""# 6. 두 영상의 합성  """

image1 = cv2.imread(IMG_DIR+'mri.png',cv2.IMREAD_GRAYSCALE)
image1 = cv2.cvtColor(image1, cv2.COLOR_GRAY2RGB)

image2 = cv2.imread(IMG_DIR+'pet.png')
image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)

plt.figure(figsize=(10, 5))
plt.subplot(1, 3, 1)
plt.title("MRI")
plt.imshow(image1, cmap='gray')
plt.subplot(1, 3, 2)
plt.title("PET")
plt.imshow(image2, cmap='gray')

alpha, beta, gamma = eval(input('alpha, beta, gamma: '))   # 0.6, 0.4, 0

dst =

plt.subplot(1, 3, 3)
plt.title("Composite image")
plt.imshow(dst)
plt.show()

"""# 7. 영상 마스킹

## 7.1 산술 연산(뺄셈)을 사용한 마스킹
"""

image1 = cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)
image2 = cv2.imread(IMG_DIR+'square_mask.png',cv2.IMREAD_GRAYSCALE)
print(image2.shape, image2[0][0])

plt.figure(figsize=(15, 7))
plt.subplot(1, 3, 1)
plt.title("Original")
plt.imshow(image1, cmap='gray', vmin=0, vmax=255)
plt.subplot(1, 3, 2)
plt.title("mask")
plt.imshow(image2, cmap='gray', vmin=0, vmax=255)

dst =

plt.subplot(1, 3, 3)
plt.title("Result")
plt.imshow(dst, cmap='gray', vmin=0, vmax=255)
plt.show()

"""## 7.2 논리연산을 이용한 마스킹"""



"""# 8. Ben Graham's preprocessing method
#### APTOS 2019 Blindness Detection 경쟁부분 우승자 Ben Graham의 전처리 방법
- https://www.kaggle.com/competitions/aptos2019-blindness-detection
- https://www.kaggle.com/code/habibmrad1983/aptos-eye-preprocessing-in-diabetic-retinopathy
"""

img = np.array([[0, 0, 0, 0, 0],
                [0, 9, 9, 9, 0],
                [0, 9, 9, 9, 0],
                [0, 9, 9, 9, 9],
                [0, 0, 0, 0, 0]])
mask =

grid =

def crop_image(img, tol=7):
    gray_img =
    mask =
    grid =

    check_shape =
    if (check_shape == 0): # image is too dark so that we crop out everything,
        return img # return original image
    else:
        img1=img[:,:,0][grid]
        img2=img[:,:,1][grid]
        img3=img[:,:,2][grid]
        img =

    return img

IMG_SIZE=224

def load_ben_color(path, tol=7, sigmaX=10):
    image = cv2.imread(path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = crop_image(image, tol)
    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))
    image=cv2.addWeighted ( image, 4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)

    return image

path= IMG_DIR+'678_left.png'

src = cv2.imread(path)
src = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)

dst =


plt.figure(figsize=(12,8))
plt.subplot(2,3,1);plt.title('Original');plt.imshow(src)
plt.subplot(2,3,2);plt.title('Transformed');plt.imshow(dst)
plt.subplot(2,3,4);
hist = cv2.calcHist(dst, [0], None, [256], [0,256])
plt.title('Histogram: R')
plt.bar(range(len(hist)), hist.flatten())

plt.subplot(2,3,5);plt.title('Histogram: G')
hist = cv2.calcHist(dst, [1], None, [256], [0,256])
plt.bar(range(len(hist)), hist.flatten())

plt.subplot(2,3,6);plt.title('Histogram: B')
hist = cv2.calcHist(dst, [2], None, [256], [0,256])
plt.bar(range(len(hist)), hist.flatten())
plt.show()

"""## 9. 특성 추출 HOG (Histogram of Orient Gradients)
- 코드 출처: https://jakevdp.github.io/PythonDataScienceHandbook/05.14-image-features.html
- https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=tommybee&logNo=221173056260
"""

from skimage import data, color, feature

image = data.chelsea()
image = color.rgb2gray(data.chelsea())
#image = cv2.imread(IMG_DIR+'lena.jpg', cv2.IMREAD_GRAYSCALE)

hog_vec, hog_image = feature.hog(image, visualize=True)

fig, ax = plt.subplots(1, 2, figsize=(12, 6),
                      subplot_kw = dict(xticks=[], yticks=[]))
ax[0].imshow(image, cmap='gray')
ax[0].set_title('input image')

ax[1].imshow(hog_image, cmap='Grays')
ax[1].set_title('Visualization of HOG features')

"""# 10. 영상이진화: Thresholding, Binarization"""

image = cv2.imread(IMG_DIR+'678_left.png',cv2.IMREAD_GRAYSCALE)

plt.figure(figsize=(10, 5))
plt.subplot(1, 3, 1)
plt.title("Original: Gray")
plt.imshow(image, cmap='gray', vmin=0, vmax=255)

plt.subplot(1, 3, 2)
# It's good practice to blur images as it removes noise
image = cv2.GaussianBlur(image, (3, 3), 0)

# Using adaptiveThreshold
th1 = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                               cv2.THRESH_BINARY, 3, 5)  # C: 1, 2, 3, 4, 5
plt.title("Adaptive Mean Thresholding")
plt.imshow(th1, cmap='gray', vmin=0, vmax=255)

th2 = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                               cv2.THRESH_BINARY, 3, 5) # C: 1, 2,3, 4, 5
plt.subplot(1,3,3)
plt.title("Adaptive Gaussian Thresholding")
plt.imshow(th2, cmap='gray', vmin=0, vmax=255)
plt.show()

"""# 10. 윤곽선(contour) 추출"""

image = cv2.imread(IMG_DIR+'right04.jpg',cv2.IMREAD_GRAYSCALE)

th, binary = cv2.threshold(image,  )

contours, hierarchy = cv2.findContours(binary,  )
src = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)

n_contours = len(contours)

for i in range(n_contours):
    cv2.drawContours(src, [contours[i]], 0, (0, 0, 255), 2)

plt.figure(figsize=(20, 10))
plt.subplot(1, 2, 1);plt.title("Original");plt.imshow(image, cmap='gray')
plt.subplot(1, 2, 2);plt.title("Result");plt.imshow(src)
plt.show()

"""# 11. 템플릿 매칭"""

# 영상에서 템플릿 영상과일치하는 곳 찾기
src = cv2.imread(IMG_DIR +'chest_05.png', cv2.IMREAD_GRAYSCALE)
templ = cv2.imread(IMG_DIR+'chest_template.png', cv2.IMREAD_GRAYSCALE)

# 탬플릿 매칭 & 결과 분석
res = cv2.matchTemplate(src, templ,  )

# 최솟값 0, 최댓값 255 지정하여 결과값을 그레이스케일 영상으로 만들기
res_norm = cv2.normalize(res, )

# 최댓값을 찾아야하므로 minmaxloc 사용,  max, min좌표, max좌표 반환
_, maxv, _, maxloc = cv2.minMaxLoc(res)

# 매칭 결과를 빨간색 사각형으로 표시
th, tw = templ.shape[:2]
dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)
cv2.rectangle(dst, maxloc, (maxloc[0] + tw, maxloc[1] + th), (255, 0, 0), 2)

plt.figure(figsize=(10, 10))
plt.subplot(2, 2, 1);plt.title("Result");plt.imshow(dst)
plt.subplot(2, 2, 2);plt.title("Original");plt.imshow(src, cmap='gray')
plt.subplot(2, 2, 3);plt.title("Template");plt.imshow(templ, cmap='gray')
plt.subplot(2, 2, 4);plt.title("res_norm");plt.imshow(res_norm, cmap='gray')
plt.show()

# 템플릿이 회전된 형태로 있는 경우에 찾을 수 있는가?

# 템플릿의 크기가 작은 경우에도 찾을 수 있는가?

"""# 얼굴 인식"""

!wget https://github.com/TUIlmenauAMS/Videocoding/raw/main/seminars/videos/videorec.mp4

import cv2
import imageio
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from skimage.transform import resize
from IPython.display import HTML

# 가중치 파일 경로
cascade_filename =IMG_DIR+'/haarcascade_frontalface_alt.xml'
# 모델 불러오기
cascade = cv2.CascadeClassifier(cascade_filename)

if not cascade:
    print('no cascade file')

def display_video(video):
    fig = plt.figure(figsize=(3,3))  #Display size specification

    mov = []
    for img in video:  #Append videos one by one to mov
        # 그레이 스케일 변환
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # cascade 얼굴 탐지 알고리즘
        results = cascade.detectMultiScale(gray,            # 입력 이미지
                                            scaleFactor= 1.1,# 이미지 피라미드 스케일 factor
                                            minNeighbors=5,  # 인접 객체 최소 거리 픽셀
                                            minSize=(20,20)  # 탐지 객체 최소 크기
                                            )
        for box in results:
            x, y, w, h = box
            cv2.rectangle(img, (x,y), (x+w, y+h), (255,255,255), thickness=2)
        img = plt.imshow(img, animated=True)
        plt.axis('off')
        mov.append([img])

    #Animation creation
    anime = animation.ArtistAnimation(fig, mov, interval=50, repeat_delay=20)

    plt.close()
    return anime

video = imageio.mimread(IMG_DIR+'videorec.mp4')  #Loading video
HTML(display_video(video).to_html5_video())  #Inline video display in HTML5