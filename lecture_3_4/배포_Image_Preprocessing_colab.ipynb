{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YkQ0d8k0iJQ"
      },
      "source": [
        "# **About OpenCV**\n",
        "* Officially launched in 1999, OpenCV (Open Source Computer Vision) from an Intel initiative.\n",
        "* OpenCV‚Äôs core is written in C++. In python we are simply using a wrapper that executes C++ code inside of python.\n",
        "* First major release 1.0 was in 2006, second in 2009, third in 2015 and 4th in 2018. with OpenCV 4.0 Beta.\n",
        "* It is an Open source library containing over 2500 optimized algorithms.\n",
        "* It is EXTREMELY useful for almost all computer vision applications and is supported on Windows, Linux, MacOS, Android, iOS with bindings to Python, Java and Matlab.\n",
        "* https://docs.opencv.org/4.x/index.html\n",
        "- https://docs.opencv.org/4.5.4/d7/da8/tutorial_table_of_content_imgproc.html\n",
        "- https://docs.opencv.org/4.x/d9/df8/tutorial_root.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML4-PAIv9fgT",
        "outputId": "80e7085a-578c-4dc2-fe9f-fa8cf8d03744"
      },
      "outputs": [],
      "source": [
        "!pip install pydicom -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jATMSrFa0iJR"
      },
      "source": [
        "# ÌååÏùº Îã§Ïö¥Î°úÎìú\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY8JY7GR8163",
        "outputId": "61ccc293-406a-4bb7-d3e1-e75388f36fb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "imgproc-master/ ÎîîÎ†âÌÜ†Î¶¨Ïóê ÏïïÏ∂ïÏù¥ Ìï¥Ï†úÎêòÏóàÏäµÎãàÎã§.\n",
            "imgproc.zip ÏÇ≠Ï†ú ÏôÑÎ£å\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "# imgproc ÌååÏùº Îã§Ïö¥Î°úÎìú Î∞è ÏïïÏ∂ïÌï¥Ï†ú\n",
        "zip_url = \"https://github.com/bykim9988/imgproc/archive/refs/heads/master.zip\"\n",
        "zip_file = \"imgproc.zip\"\n",
        "IMG_DIR = \"imgproc-master/\"\n",
        "\n",
        "# Îã§Ïö¥Î°úÎìú\n",
        "urllib.request.urlretrieve(zip_url, zip_file)\n",
        "\n",
        "# ÏïïÏ∂ï Ìï¥Ï†ú\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "# Í≤∞Í≥º ÌôïÏù∏\n",
        "print(f\"{IMG_DIR} ÎîîÎ†âÌÜ†Î¶¨Ïóê ÏïïÏ∂ïÏù¥ Ìï¥Ï†úÎêòÏóàÏäµÎãàÎã§.\")\n",
        "\n",
        "if os.path.exists(zip_file):\n",
        "    os.remove(zip_file)\n",
        "    print(f\"{zip_file} ÏÇ≠Ï†ú ÏôÑÎ£å\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'f:\\\\ÌïôÏäµÏûêÎ£å\\\\ai_lecture\\\\lecture_3_4'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7dbnrdb0iJS"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unexpected character after line continuation character (3240176581.py, line 10)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(f\"\\\\nüìÅ ÌååÏùº: {os.path.basename(file\\_path)}\")\u001b[39m\n                                            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unexpected character after line continuation character\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pydicom as dicom\n",
        "from pprint import pprint\n",
        "\n",
        "def analyze_dicom(file_path):\n",
        "    try:\n",
        "        ds = dicom.dcmread(file_path)\n",
        "        modality = ds.get(\"Modality\", \"Unknown\")\n",
        "        print(f\"\\\\nüìÅ ÌååÏùº: {os.path.basename(file_path)}\")\n",
        "        print(f\"üß™ Modality: {modality}\")\n",
        "        print(\"üìå Ï£ºÏöî Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú:\")\n",
        "        print(f\"  \\- Patient Name: {ds.get('PatientName', 'N/A')}\")\n",
        "        print(f\"  \\- Study Date: {ds.get('StudyDate', 'N/A')}\")\n",
        "        print(f\"  \\- Rows x Columns: {ds.get('Rows', 'N/A')} x {ds.get('Columns', 'N/A')}\")\n",
        "\n",
        "        if modality \\== \"CT\":\n",
        "            print(f\"  \\- Slice Thickness: {ds.get('SliceThickness', 'N/A')} mm\")\n",
        "            print(f\"  \\- KVP: {ds.get('KVP', 'N/A')}\")\n",
        "            print(f\"  \\- Rescale Slope / Intercept: {ds.get('RescaleSlope', 'N/A')} / {ds.get('RescaleIntercept', 'N/A')}\")\n",
        "        elif modality \\== \"MR\":\n",
        "            print(f\"  \\- Repetition Time (TR): {ds.get('RepetitionTime', 'N/A')} ms\")\n",
        "            print(f\"  \\- Echo Time (TE): {ds.get('EchoTime', 'N/A')} ms\")\n",
        "            print(f\"  \\- Flip Angle: {ds.get('FlipAngle', 'N/A')}\")\n",
        "        elif modality in \\[\"CR\", \"DX\"\\]:  \\# X-ray Í≥ÑÏó¥\n",
        "            print(f\"  \\- View Position: {ds.get('ViewPosition', 'N/A')}\")\n",
        "            print(f\"  \\- Exposure Time: {ds.get('ExposureTime', 'N/A')} ms\")\n",
        "            print(f\"  \\- X-Ray Tube Current: {ds.get('XRayTubeCurrent', 'N/A')} mA\")\n",
        "        elif modality \\== \"US\":\n",
        "            print(f\"  \\- Number of Frames: {ds.get('NumberOfFrames', 'N/A')}\")\n",
        "            print(f\"  \\- Frame Time: {ds.get('FrameTime', 'N/A')} ms\")\n",
        "        elif modality \\== \"PT\":  \\# PET\n",
        "            print(f\"  \\- Radiopharmaceutical: {ds.get('Radiopharmaceutical', 'N/A')}\")\n",
        "            print(f\"  \\- Total Dose: {ds.get('RadionuclideTotalDose', 'N/A')} Bq\")\n",
        "        else:\n",
        "            print(\"  \\- (Ìï¥Îãπ modalityÏóê ÌäπÌôîÎêú Ï†ïÎ≥¥ ÏóÜÏùå)\")\n",
        "\n",
        "        print(f\"  \\- Bits Allocated....: {ds.BitsAllocated}\")\n",
        "        print(f\"  \\- Bits Stored.......: {ds.BitsStored}\")\n",
        "        print(f\"  \\- High Bit..........: {ds.HighBit}\")\n",
        "        print(f\"  \\- raw image max val.: {ds.pixel\\_array.max()}\" )\n",
        "        print(f\"  \\- raw image min val.: {ds.pixel\\_array.min()}\")\n",
        "        if hasattr(ds, 'WindowCenter'):\n",
        "            print(f\"  \\- WindowCenter......: {ds.WindowCenter}\" )\n",
        "        if hasattr(ds, 'WindowWidth'):\n",
        "            print(f\"  \\- WindowWidth.......: {ds.WindowWidth}\" )\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Ïò§Î•ò Î∞úÏÉù \\- {file\\_path}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szy9ZGV_Mwps"
      },
      "outputs": [],
      "source": [
        "img_list = ['chest_01.png', 'chest_02.png','chest_03.png']\n",
        "for file in img_list:\n",
        "    file_path = IMG_DIR + file\n",
        "    image1 = plt.imread(file_path)\n",
        "    print(f\"FILE........: {file_path}\")\n",
        "    print(f\"Original....: {image1.min()}, {image1.max() }\")\n",
        "    image2 = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "    print(f\"GrayScaled..: {image2.min()}, {image2.max() }\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLE--wfL0iJS"
      },
      "source": [
        "# 1. Í∑∏Î†àÏù¥ ÏòÅÏÉÅÍ≥º Ïª¨Îü¨ÏòÅÏÉÅ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrnFOLWX0iJS"
      },
      "outputs": [],
      "source": [
        "image1 =  cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "image2 = cv2.imread( )\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Gray image\")\n",
        "plt.imshow(image1, cmap='gray')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Color image\")\n",
        "plt.imshow(image2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-87KuLL0iJT"
      },
      "source": [
        "### color ÏòÅÏÉÅÏùÑ R, G, B Í∞Å ÏòÅÏÉÅÏúºÎ°ú Î∂ÑÌï†Ìï¥ Î≥¥Í∏∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP6MIKNQ2-vM"
      },
      "outputs": [],
      "source": [
        "image2 = cv2.imread(  )\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.subplot(2, 4, 1)\n",
        "plt.title(\"Original image\")\n",
        "plt.imshow(image2)\n",
        "plt.subplot(2, 4, 2)\n",
        "plt.title(\"Red\")\n",
        "plt.imshow(image2[:,:,0], cmap='Reds', vmin=0, vmax=255)\n",
        "plt.subplot(2, 4, 3)\n",
        "plt.title(\"Green\")\n",
        "plt.imshow(image2[:,:,1], cmap='Greens', vmin=0, vmax=255)\n",
        "plt.subplot(2, 4, 4)\n",
        "plt.title(\"Blue\")\n",
        "plt.imshow(image2[:,:,2], cmap='Blues', vmin=0, vmax=255)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuqRzWQ1-YPI"
      },
      "source": [
        "# # ÏòÅÏÉÅ Ï†ïÍ∑úÌôî"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1s1Z5aEW-Vti"
      },
      "outputs": [],
      "source": [
        "image1 = cv2.imread( )\n",
        "scaled =\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.title(\"Original Image\"+\": range %d~%d\"%(image1.min(), image1.max()))\n",
        "plt.imshow(image1, cmap='gray', vmin=0, vmax=255)\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.title(\"MinMax Scaled\"+\": range %.2f~%.2f\"%(scaled.min(), scaled.max()))\n",
        "plt.imshow(scaled, cmap='gray', vmin=0.0, vmax=1.0)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4khxe67-5DM"
      },
      "source": [
        "## ‚óè Îç∞Ïù¥ÌÑ∞ Ï¶ùÍ∞ïÏùÑ ÏúÑÌïú Ï†ÑÏ≤òÎ¶¨ ÎèÑÍµ¨ ImageDataGenerator\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "- ÏùòÎ£å Îç∞Ïù¥ÌÑ∞ Ï¶ùÍ∞ï Ï∞∏Í≥† ÎÖºÎ¨∏:\n",
        "- - Îî•Îü¨Îãù Í∏∞Î∞ò ÏùòÎ£å ÏòÅÏÉÅ Î∂ÑÏÑùÏùÑ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ Ï¶ùÍ∞ï Í∏∞Î≤ï, ÎåÄÌïú ÏùòÌïô ÏòÅÏÉÅÌïôÌöåÏßÄ, 2020.81(6)\n",
        "- - https://pmc.ncbi.nlm.nih.gov/articles/PMC9431833/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPu6z_Zt5kXi"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "file_list = ['chest_01.png', 'chest_02.png','chest_03.png']\n",
        "\n",
        "img_list = []\n",
        "for file in file_list:\n",
        "    file_path = IMG_DIR + file\n",
        "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    img_list.append(img)\n",
        "\n",
        "x_train = np.array(img_list)\n",
        "y_train = np.array([0,1,2])\n",
        "\n",
        "class_names=['X_ray0','X_ray1','X_ray2']\n",
        "\n",
        "\n",
        "batch_siz=3\n",
        "generator=ImageDataGenerator(rotation_range= ,\n",
        "                             width_shift_range= ,\n",
        "                             height_shift_range= ,\n",
        "                             shear_range= ,\n",
        "                             zoom_range= ,\n",
        "                             horizontal_flip= )\n",
        "gen=generator.flow(   )\n",
        "\n",
        "for a in range(10):\n",
        "    img,label=next(gen)\n",
        "    plt.figure(figsize=(8, 3))\n",
        "    plt.suptitle(\"Generator trial \"+str(a+1))\n",
        "    for i in range(batch_siz):\n",
        "        plt.subplot(1, batch_siz, i+1)\n",
        "        plt.imshow(  )\n",
        "        plt.xticks([]); plt.yticks([]); plt.grid(False)\n",
        "        plt.title(class_names[int(label[i])])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4goJywiY0iJU"
      },
      "source": [
        "# 2.ÌûàÏä§ÌÜ†Í∑∏Îû®"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YrXr76_0iJU"
      },
      "source": [
        "- https://docs.opencv.org/4.5.4/d8/dbc/tutorial_histogram_calculation.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogNRoZZK0iJU"
      },
      "source": [
        "## 2.1 ÌûàÏä§ÌÜ†Í∑∏Îû® Í≥ÑÏÇ∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSnp3Al60iJU"
      },
      "outputs": [],
      "source": [
        "image1 = cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)\n",
        "image1_hist =\n",
        "\n",
        "image2 = cv2.imread(IMG_DIR+'chest_02.png',cv2.IMREAD_GRAYSCALE)\n",
        "image2_hist =\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.title(\"Gray image\")\n",
        "plt.imshow(image1, cmap='gray', vmin=0, vmax=255)\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.title(\"Histogram\")\n",
        "plt.bar(range(len(image1_hist)), image1_hist.reshape(-1,))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwwueYzr0iJU"
      },
      "source": [
        "## 2.2 ÌûàÏä§ÌÜ†Í∑∏Îû® Ïä§Ìä∏Î†àÏπ≠Í≥º ÌèâÌôúÌôî"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYYmYjloANMj"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(IMG_DIR+'chest_02.png',cv2.IMREAD_GRAYSCALE)\n",
        "img_hist =\n",
        "\n",
        "# ÌûàÏä§ÌÜ†Í∑∏Îû® Ïä§Ìä∏Î†àÏπ≠\n",
        "def histogram_stretching(img, new_min=0, new_max=255):\n",
        "    min_val = np.min(img)\n",
        "    max_val = np.max(img)\n",
        "    stretched = ((img - min_val) / (max_val - min_val) * (new_max - new_min) + new_min).astype(np.uint8)\n",
        "    return stretched\n",
        "\n",
        "# ÌûàÏä§ÌÜ†Í∑∏Îû® Ïù¥ÌÄÑÎùºÏù¥Ï†úÏù¥ÏÖò\n",
        "equalized =\n",
        "\n",
        "# ÌûàÏä§ÌÜ†Í∑∏Îû® Ïä§Ìä∏Î†àÏπ≠ Ï†ÅÏö©\n",
        "stretched =\n",
        "\n",
        "# Í≤∞Í≥º ÏãúÍ∞ÅÌôî\n",
        "titles = ['Original', 'Stretched', 'Equalized']\n",
        "images = [img, stretched, equalized]\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(3):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(images[i], cmap='gray' )\n",
        "    plt.title(titles[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(2, 3, i+4)\n",
        "    plt.hist(images[i].flatten(), 256, [0, 256])\n",
        "    plt.title(titles[i] + ' Histogram')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlQKnxo_2DSm"
      },
      "source": [
        "# 3. Affine Transform\n",
        "\n",
        "- https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga0203d9ee5fcd28d40dbc4a1ea4451983"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii6W9MVdh5kM"
      },
      "source": [
        "## 3.1 ÌèâÌñâ Ïù¥Îèô"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu4ttZcah4ra"
      },
      "outputs": [],
      "source": [
        "src = cv2.imread(IMG_DIR+'chest_06.png',cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "dx, dy = eval(input('xÏ∂ï Ïù¥ÎèôÍ±∞Î¶¨, yÏ∂ïÏù¥Îèô Í±∞Î¶¨ : '))\n",
        "\n",
        "# np.arrayÎ°ú Affine ÌñâÎ†¨ ÏÉùÏÑ±\n",
        "aff =\n",
        "\n",
        "dst =\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original image\")\n",
        "plt.imshow(src, cmap='gray')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Result\")\n",
        "plt.imshow(dst, cmap='gray')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABUqmnLN2G0U"
      },
      "source": [
        "## 3.2 Affine Transform: ÌöåÏ†Ñ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSxdMK7o0iJW"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "\n",
        "theta = int(input('ÌöåÏ†Ñ Í∞ÅÎèÑ: '))\n",
        "rad = theta * math.pi / 180 # Í∞ÅÎèÑ ÏÑ§Ï†ï\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8NMbv85AmJh"
      },
      "outputs": [],
      "source": [
        "# ÏòÅÏÉÅÏùò Ï§ëÏã¨ÏùÑ Í∏∞Ï§ÄÏúºÎ°ú ÌöåÏ†Ñ\n",
        "\n",
        "\n",
        "# Ïù¥ÎØ∏ÏßÄÏùò Ï§ëÏã¨ Ï¢åÌëú Í≥ÑÏÇ∞\n",
        "(h, w) = src.shape[:2]\n",
        "center = (w // 2, h // 2)\n",
        "# Ïä§ÏºÄÏùº ÏÑ§Ï†ï (1.0ÏùÄ ÏõêÎ≥∏ ÌÅ¨Í∏∞ Ïú†ÏßÄ)\n",
        "scale = 1.0\n",
        "\n",
        "# ÌöåÏ†Ñ ÌñâÎ†¨ ÏÉùÏÑ±\n",
        "aff =\n",
        "dst =\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjwaOS6h4Tvc"
      },
      "source": [
        "## 3.3 Affine Transform: ÌôïÎåÄ, Ï∂ïÏÜå"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5exW7lG5VKG"
      },
      "source": [
        "### ‚ñ∂ ÌôïÎåÄ ÌõÑ: Î¨ºÏ≤¥Í∞Ä Ï§ëÏïôÏóê ÏúÑÏπòÌïòÎèÑÎ°ù ÏÉÅ,Ìïò,Ï¢å,Ïö∞ shift ÌïÑÏöî\n",
        "- imageGeneratorÏóêÏÑúÎäî ÌôïÎåÄ scaleÍ≥º shift Í∞ôÏù¥..\n",
        "\n",
        "### ‚ñ∂ Ï∂ïÏÜå ÌõÑ: Î¨ºÏ≤¥Í∞Ä Ï§ëÏïôÏóê ÏúÑÏπòÌïòÎ©¥ÏÑú ÏõêÏòÅÏÉÅ ÌÅ¨Í∏∞Î°ú Ï°∞Ï†ï ÌïÑÏöî"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfLIuUxu5aHQ"
      },
      "outputs": [],
      "source": [
        "src = cv2.imread(IMG_DIR+'678_left.png')\n",
        "src = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
        "height, width, channel = src.shape\n",
        "\n",
        "alpha = 1.2   # ÌôïÎåÄ\n",
        "\n",
        "dst =\n",
        "\n",
        "s_x =\n",
        "s_y =\n",
        "\n",
        "print(f'Î≥µÏÇ¨ ÏãúÏûë ÏúÑÏπò: ({s_y:d}, {s_x:d}), ÌôïÎåÄ ÌõÑ(Ìè≠: {s_w}, ÎÜíÏù¥: {s_h})')\n",
        "dst1 = np.zeros_like(src)\n",
        "\n",
        "\n",
        "beta = 0.9    # Ï∂ïÏÜå\n",
        "s_w =\n",
        "s_h =\n",
        "\n",
        "dst2 = np.zeros_like(src)\n",
        "s_y =\n",
        "s_x =\n",
        "dst2\n",
        "print(f'Î≥µÏÇ¨ ÏãúÏûë ÏúÑÏπò: ({s_y:d}, {s_x:d}), Ï∂ïÏÜå ÌõÑ(Ìè≠: {s_w}, ÎÜíÏù¥: {s_h})')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Original image\")\n",
        "plt.imshow(src)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"Enlarged\")\n",
        "plt.imshow(dst1)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"Reduced: Centered\")\n",
        "plt.imshow(dst2)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN68ZdNq5ugH"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(IMG_DIR+'butterfly.jpg')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.title(\"Original\")\n",
        "plt.imshow(image)\n",
        "\n",
        "# 3/4 Î∞∞Î°ú\n",
        "image_scaled = cv2.resize(  )\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.title(f\"Reduced:{image_scaled.shape[1]:d} X {image_scaled.shape[0]:d}\")\n",
        "plt.imshow(image_scaled)\n",
        "\n",
        "# 2Î∞∞Î°ú ÌÅ¨Í≤å\n",
        "img_scaled = cv2.resize(  )\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.title(f\"Enlarged:{img_scaled.shape[1]:d} X {img_scaled.shape[0]:d}\")\n",
        "plt.imshow(img_scaled)\n",
        "\n",
        "# 224x224Î°ú ÌÅ¨Í∏∞ Î≥ÄÌôò\n",
        "img_scaled = cv2.resize(  )\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.title(f\"{img_scaled.shape[1]:d} X {img_scaled.shape[0]:d} resized\")\n",
        "plt.imshow(img_scaled)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlXlimO90iJW"
      },
      "source": [
        "# 3.3. ÎåÄÏπ≠(flip)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b5kM8jG0iJW"
      },
      "outputs": [],
      "source": [
        "src = cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)\n",
        "dst1 =\n",
        "dst2 =\n",
        "dst3 =\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.title(\"Original image\")\n",
        "plt.imshow(src, cmap='gray', vmin=0, vmax=255)\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.title(\"Vertical flip\")\n",
        "plt.imshow(dst1, cmap='gray', vmin=0, vmax=255)\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.title(\"Horizontal flip\")\n",
        "plt.imshow(dst2, cmap='gray', vmin=0, vmax=255)\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.title(\"Antipodal mapping\")\n",
        "plt.imshow(dst3, cmap='gray', vmin=0, vmax=255)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5qsdAQiddQZ"
      },
      "source": [
        "# 4. Ìë∏Î¶¨Ïóê Î≥ÄÌôò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5MWubvIM8ku"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ÏÉòÌîåÎßÅ ÌååÎùºÎØ∏ÌÑ∞\n",
        "fs = 500          # ÏÉòÌîåÎßÅ Ï£ºÌååÏàò (Hz)\n",
        "T = 2             # Ïã†Ìò∏ Í∏∏Ïù¥ (Ï¥à)\n",
        "t = np.linspace(0, T, fs * T, endpoint=False)\n",
        "\n",
        "# Ï£ºÌååÏàò ÏÑ±Î∂ÑÎ≥Ñ Ïã†Ìò∏ ÏÉùÏÑ±\n",
        "sig_2hz =   np.sin(2 * np.pi * 2 * t)\n",
        "sig_3hz =   np.sin(2 * np.pi * 3 * t)       # dominant\n",
        "sig_7hz =   np.sin(2 * np.pi * 7 * t)\n",
        "sig_10hz =   np.sin(2 * np.pi * 10 * t)\n",
        "sig_20hz =   np.sin(2 * np.pi * 20 * t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMBDs_0jNsfM"
      },
      "outputs": [],
      "source": [
        "# ‚ñ∂ ÎàÑÏ†Å Ìï©ÏÑ± Ïã†Ìò∏\n",
        "sum1 = sig_2hz\n",
        "sum2 = sum1 + sig_3hz\n",
        "sum3 = sum2 + sig_7hz\n",
        "sum4 = sum3 + sig_10hz\n",
        "sum5 = sum4 + sig_20hz  # ÏµúÏ¢Ö Ïã†Ìò∏\n",
        "\n",
        "# ‚ñ∂ ÏãúÍ∞ÅÌôî\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(511); plt.plot(t, sum1); plt.title(\"2Hz\")\n",
        "plt.subplot(512); plt.plot(t, sum2); plt.title(\"2Hz + 3Hz\")\n",
        "plt.subplot(513); plt.plot(t, sum3); plt.title(\"2Hz + 3Hz + 7Hz\")\n",
        "plt.subplot(514); plt.plot(t, sum4); plt.title(\"2Hz + 3Hz + 7Hz + 10Hz\")\n",
        "plt.subplot(515); plt.plot(t, sum5); plt.title(\"ÏµúÏ¢Ö Ìï©ÏÑ± Ïã†Ìò∏\")\n",
        "plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u8QTJvNN4ny"
      },
      "outputs": [],
      "source": [
        "from scipy.fft import fft, fftfreq, ifft\n",
        "\n",
        "# Ìï©ÏÑ± Ïã†Ìò∏\n",
        "composite_signal = sig_2hz + sig_3hz + sig_7hz + sig_10hz + sig_20hz\n",
        "\n",
        "# Ìë∏Î¶¨Ïóê Î≥ÄÌôò\n",
        "N = len(composite_signal)\n",
        "yf = fft(composite_signal)\n",
        "xf = fftfreq(N, 1/fs)\n",
        "\n",
        "# ÏßÑÌè≠ Í≥ÑÏÇ∞ Î∞è Ï†ïÎ†¨\n",
        "amplitude = np.abs(yf) / N\n",
        "pos_mask = (xf >= 0)\n",
        "xf_pos = xf[pos_mask]\n",
        "amp_pos = amplitude[pos_mask]\n",
        "sorted_indices = np.argsort(amp_pos)[::-1]  # ÏßÑÌè≠ ÎÇ¥Î¶ºÏ∞®Ïàú\n",
        "\n",
        "print(\"Ï£ºÌååÏàò ÏÑ±Î∂Ñ Ï†ïÎ†¨:\")\n",
        "for i in range(5):\n",
        "    freq = xf_pos[sorted_indices[i]]\n",
        "    amp = amp_pos[sorted_indices[i]]\n",
        "    print(f\"{i+1}) {freq:.2f} Hz: amplitude={amp:.3f}\")\n",
        "\n",
        "# ÏãúÍ∞ÅÌôî\n",
        "plt.figure(figsize=(12, 4)); plt.plot(xf_pos, amp_pos)\n",
        "plt.title(\"Ìï©ÏÑ± Ïã†Ìò∏Ïùò Ï£ºÌååÏàò Ïä§ÌéôÌä∏Îüº (FFT)\"); plt.xlabel(\"Frequency (Hz)\")\n",
        "plt.ylabel(\"Amplitude\"); plt.grid(True)\n",
        "plt.xlim(0, 30)  # Î∂ÑÏÑù Î≤îÏúÑ Ï†úÌïú\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMIo4qHUdcuI"
      },
      "outputs": [],
      "source": [
        "a = np.repeat([0, 255], 10)\n",
        "gray = np.tile(a, (100, 10))\n",
        "\n",
        "f_img = np.fft. (gray)\n",
        "fimg =  np.fft. (f_img)\n",
        "\n",
        "mag = 20*np.log(np.abs(fimg)+1)\n",
        "i_fft = np.fft. (f_img)\n",
        "i_fft = np. (i_fft)\n",
        "\n",
        "\n",
        "plt.figure( figsize = (20, 10))\n",
        "plt.subplot(131)\n",
        "plt.imshow(gray, cmap = 'gray')\n",
        "plt.subplot(132)\n",
        "plt.imshow(mag, cmap = 'gray')\n",
        "plt.subplot(133)\n",
        "plt.imshow(i_fft, cmap = 'gray')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1qYHykjePFv"
      },
      "source": [
        "## OpenCV Ìë∏Î¶¨Ïóê Î≥ÄÌôò\n",
        "- dft:  https://docs.opencv.org/3.4/d8/d01/tutorial_discrete_fourier_transform.html\n",
        "- idft: https://docs.opencv.org/3.4/d2/de8/group__core__array.html#gaa708aa2d2e57a508f968eb0f69aa5ff1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qS9cO63hzeN"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)\n",
        "dft = cv2. (np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
        "dft_shift = np.fft. (dft)\n",
        "\n",
        "mag = 20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]) + 1)\n",
        "\n",
        "rows, cols = img.shape\n",
        "crow,ccol = rows//2 , cols//2\n",
        "\n",
        "# Low-pass Filtering\n",
        "mask = np. ((rows,cols, 2),np.uint8)\n",
        "mask[crow-50:crow+50, ccol-50:ccol+50] =\n",
        "\n",
        "f_shift = dft_shift\n",
        "idft_shift = np.fft.fftshift( f_shift )\n",
        "i_fft =  cv2.idft( idft_shift)\n",
        "i_fft = cv2.magnitude(i_fft[:,:,0], i_fft[:,:,1])\n",
        "\n",
        "plt.figure( figsize = (20, 5) )\n",
        "plt.subplot(141),plt.imshow(img, cmap = 'gray')\n",
        "plt.title('Input Image'); plt.xticks([]); plt.yticks([])\n",
        "plt.subplot(142),plt.imshow(mag, cmap = 'gray')\n",
        "plt.title('Magnitude Spectrum'); plt.xticks([]); plt.yticks([])\n",
        "plt.subplot(143),plt.imshow( mask[:,:,0], cmap = 'gray')\n",
        "plt.title('Low-pass Filter'); plt.xticks([]); plt.yticks([])\n",
        "plt.subplot(144),plt.imshow(i_fft, cmap = 'gray')\n",
        "plt.title('Low-pass Filtered'); plt.xticks([]); plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aviGIRPRzyw"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Ïù¥ÎØ∏ÏßÄÏùò Ï§ëÏã¨ Ï¢åÌëú Í≥ÑÏÇ∞\n",
        "(h, w) = img.shape[:2]\n",
        "center = (w // 2, h // 2)\n",
        "# ÌöåÏ†Ñ ÌñâÎ†¨ ÏÉùÏÑ±\n",
        "aff = cv2.getRotationMatrix2D(center, 15, 1.0)\n",
        "dst = cv2.warpAffine(src, aff, (w, h))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fqo-2shhsnvh"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(IMG_DIR+'lena.jpg',cv2.IMREAD_GRAYSCALE)\n",
        "d\n",
        "# High-pass Filtering\n",
        "w = 60\n",
        "mask = np. ((rows,cols, 2),np.uint8)\n",
        "mask[crow-w//2:crow+w//2, ccol-w//2:ccol+w//2] =\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqp79rAO6gcx"
      },
      "source": [
        "# 5. Convolution\n",
        "- https://en.wikipedia.org/wiki/Convolution\n",
        "- https://en.wikipedia.org/wiki/Kernel_(image_processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3vRUSb30iJX"
      },
      "source": [
        "## 5.1 Convolution: Blurring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5-ueD520iJX"
      },
      "outputs": [],
      "source": [
        "image1 = cv2.imread(IMG_DIR+'pic2.png')\n",
        "src = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
        "ksize=7\n",
        "dst1=\n",
        "\n",
        "ksize=7\n",
        "dst2 =\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 3, 1);plt.title(\"Original image\");plt.imshow(src )\n",
        "plt.subplot(1, 3, 2);plt.title(\"Blurred\");plt.imshow(dst1)\n",
        "plt.subplot(1, 3, 3);plt.title(\"Gaussian blurred\");plt.imshow(dst2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8u69sZ80iJY"
      },
      "source": [
        "## 5.2 Convolution: Sharpening\n",
        "#### cv2.addWeighted\n",
        "- https://docs.opencv.org/3.4/d2/de8/group__core__array.html#gafafb2513349db3bcff51f54ee5592a19\n",
        "\n",
        "#### cv2.filter2D\n",
        "- https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#ga27c049795ce870216ddfb366086b5a04"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG4LqsUd9Emd"
      },
      "outputs": [],
      "source": [
        "image =\n",
        "\n",
        "\n",
        "kernel_sharpening = np.array([[-1,-1,-1],\n",
        "                              [-1,9,-1],\n",
        "                              [-1,-1,-1]])\n",
        "\n",
        "sharpened = cv2.filter2D(image, -1, kernel_sharpening)\n",
        "\n",
        "\n",
        "laplacian_1 = np.array([[0, -1, 0],\n",
        "                      [-1, 5, -1],\n",
        "                      [0, -1, 0]])\n",
        "laplacian_2 = np.array([[1, -2, 1],\n",
        "                      [-2, 5, -2],\n",
        "                      [1, -2, 1]])\n",
        "laplacian_1 = cv2.convertScaleAbs(cv2.filter2D(image, -1, laplacian_1))\n",
        "\n",
        "laplacian_2 = cv2.convertScaleAbs(cv2.filter2D(image, -1, laplacian_2))\n",
        "\n",
        "laplacian_sharpened = cv2.addWeighted(laplacian_1, 0.5, laplacian_2, 0.5, 0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kluCr9470iJY"
      },
      "source": [
        "## 5.3 Convolution: ÏóêÏßÄ(Î™®ÏÑúÎ¶¨) Ï∂îÏ∂ú"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9an74xcc_gT"
      },
      "source": [
        "#### edge detector Laplacian\n",
        "- https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#gad78703e4c8fe703d479c1860d76429e6\n",
        "\n",
        "#### edge detector Sobel\n",
        "- https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#gacea54f142e81b6758cb6f375ce782c8d\n",
        "\n",
        "#### edge detector Canny\n",
        "- https://docs.opencv.org/4.x/da/d5c/tutorial_canny_detector.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8-ZEXUa0iJY"
      },
      "outputs": [],
      "source": [
        "gray = cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "kernel_size = 5  # 7 --> 5Î°ú\n",
        "sobelx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, kernel_size) # Sobel_x\n",
        "   # --> CV_8UÎäî underflow, overflowÍ∞Ä ÏûàÏúºÎãà, ÏôÄ 32F Î•º ÏÇ¨Ïö©ÌïòÎäî Í≤ÉÏù¥ ÏïàÏ†ÑÌïòÎã§.\n",
        "sobely = cv2.Sobel(gray, cv2.CV_32F, 0, 1, kernel_size) # Sobel_y\n",
        "sobel = cv2.addWeighted( cv2.convertScaleAbs( sobelx ), 0.5, cv2.convertScaleAbs(sobely), 0.5, 0)\n",
        "\n",
        "laplacian = cv2.Laplacian(gray, cv2.CV_8U, ksize=kernel_size)\n",
        "canny = cv2.Canny(gray, 30, 50, L2gradient=True)\n",
        "canny2 = cv2.Canny(gray, 20, 50, L2gradient=True)\n",
        "\n",
        "ksize=5\n",
        "blur= cv2.GaussianBlur(gray, (ksize, ksize), 2)\n",
        "canny3 = cv2.Canny(blur, 40, 50, L2gradient=True)\n",
        "\n",
        "plt.figure(figsize=(20, 16))\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.title(\"Original image\")\n",
        "plt.imshow(gray, cmap='gray', vmin=0, vmax=255)\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.title(\"Sobel\")\n",
        "plt.imshow(sobel, cmap='gray')\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.title(\"Laplacian\")\n",
        "plt.imshow(laplacian, cmap='gray')\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.title(\"Canny(30-50)\")\n",
        "plt.imshow(canny, cmap='gray')\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.title(\"Canny(20-50)\")\n",
        "plt.imshow(canny2, cmap='gray')\n",
        "\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.title(\"Blurring+Canny(40-50)\")\n",
        "plt.imshow(canny3, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i6U_cgThO3V"
      },
      "outputs": [],
      "source": [
        "image1 = cv2.imread(IMG_DIR+'thermal.jpg')\n",
        "gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "kernel_size = 5\n",
        "sobel = cv2.Sobel(gray, cv2.CV_8U, 1, 0, kernel_size)\n",
        "laplacian = cv2.Laplacian(gray, cv2.CV_8U, ksize=kernel_size)\n",
        "canny = cv2.Canny(gray, 100, 180)\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.title(\"Original\")\n",
        "plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB) )\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.title(\"Gray image\")\n",
        "plt.imshow(gray, cmap='gray')\n",
        "\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.title(\"Laplacian\")\n",
        "plt.imshow(laplacian, cmap='gray')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.title(\"Canny\")\n",
        "plt.imshow(canny, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jgMF3PIdHiO"
      },
      "source": [
        "## 5.4. ÌåΩÏ∞Ω(Dilation), Ïπ®Ïãù(Erosion), Opening and Closing\n",
        "- https://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znmUpFw-kxtx"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(IMG_DIR+'LinuxLogo.jpg')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#image = cv2.imread(IMG_DIR+'lena.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(3, 2, 1)\n",
        "plt.title(\"Original\")\n",
        "plt.imshow(image)\n",
        "\n",
        "# Let's define our kernel size\n",
        "kernel = np.ones((5,5), np.uint8)\n",
        "\n",
        "# Now we erode\n",
        "erosion = cv2.erode(image, kernel, iterations = 1)\n",
        "plt.subplot(3, 2, 2)\n",
        "plt.title(\"Erosion\")\n",
        "plt.imshow(erosion)\n",
        "\n",
        "dilation = cv2.dilate(image, kernel, iterations = 1)\n",
        "plt.subplot(3, 2, 3)\n",
        "plt.title(\"Dilation\")\n",
        "plt.imshow(dilation)\n",
        "\n",
        "# Opening - Good for removing noise\n",
        "opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
        "plt.subplot(3, 2, 4)\n",
        "plt.title(\"Opening\")\n",
        "plt.imshow(opening)\n",
        "\n",
        "# Closing - Good for removing noise\n",
        "closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
        "plt.subplot(3, 2, 5)\n",
        "plt.title(\"Closing\")\n",
        "plt.imshow(closing)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh0hToog5x3M",
        "outputId": "12fadef8-8068-4b4f-c02d-68785ff3759a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.11/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydicom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DM1WVhev5r2u"
      },
      "outputs": [],
      "source": [
        "from pydicom import dcmread\n",
        "ds= dcmread(IMG_DIR + '00ac73cfc372.dcm' )\n",
        "image = ds.pixel_array.copy()\n",
        "\n",
        "\n",
        "rescaled_image = image * ds.RescaleSlope + ds.RescaleIntercept\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(rescaled_image, cmap=\"gray\")\n",
        "plt.grid(False)\n",
        "plt.title(\"Rescaled\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpmu5vYf8whC"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "plt.subplot(3, 3, 1)\n",
        "plt.title(\"Original\")\n",
        "plt.imshow(rescaled_image, cmap='gray')\n",
        "\n",
        "# Let's define our kernel size\n",
        "\n",
        "\n",
        "# Now we erode\n",
        "erosion =\n",
        "plt.subplot(3, 3, 2)\n",
        "plt.title(\"Erosion\")\n",
        "plt.imshow(erosion, cmap='gray')\n",
        "\n",
        "dilation =\n",
        "plt.subplot(3, 3, 3)\n",
        "plt.title(\"Dilation\")\n",
        "plt.imshow(dilation, cmap='gray')\n",
        "\n",
        "# Opening - Good for removing noise\n",
        "dst1 =\n",
        "dst1 =\n",
        "plt.subplot(3, 3, 5)\n",
        "plt.title(\"Opening\")\n",
        "plt.imshow(dst1, cmap='gray')\n",
        "\n",
        "# Closing - Good for removing noise\n",
        "dst2 = cv2.morphologyEx(rescaled_image, cv2.MORPH_CLOSE, kernel)\n",
        "plt.subplot(3, 3, 6)\n",
        "plt.title(\"Closing\")\n",
        "plt.imshow(dst2, cmap='gray')\n",
        "\n",
        "plt.subplot(3, 3, 4)\n",
        "plt.title(\"dst3:Original - Opening\")\n",
        "dst3 =\n",
        "plt.imshow(dst3, cmap='gray')\n",
        "\n",
        "plt.subplot(3, 3, 7)\n",
        "plt.title(\"dst4: rescaled - dst3\")\n",
        "dst4 =\n",
        "plt.imshow(dst4, cmap='gray')\n",
        "\n",
        "plt.subplot(3, 3, 8)\n",
        "th,binary1 =\n",
        "plt.title(f\"segmentated by dst4: thr={th:.2f}\")\n",
        "plt.imshow(binary1, cmap='gray')\n",
        "\n",
        "plt.subplot(3, 3, 9)\n",
        "th,binary2 =\n",
        "plt.title(f\"segmentated by rescaled_image: thr={th:.2f}\")\n",
        "plt.imshow(binary2, cmap='gray')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOcf6N4xeJMP"
      },
      "source": [
        "# 6. Îëê ÏòÅÏÉÅÏùò Ìï©ÏÑ±  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fpcb6B3b0iJZ"
      },
      "outputs": [],
      "source": [
        "image1 = cv2.imread(IMG_DIR+'mri.png',cv2.IMREAD_GRAYSCALE)\n",
        "image1 = cv2.cvtColor(image1, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "image2 = cv2.imread(IMG_DIR+'pet.png')\n",
        "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"MRI\")\n",
        "plt.imshow(image1, cmap='gray')\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"PET\")\n",
        "plt.imshow(image2, cmap='gray')\n",
        "\n",
        "alpha, beta, gamma = eval(input('alpha, beta, gamma: '))   # 0.6, 0.4, 0\n",
        "\n",
        "dst =\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"Composite image\")\n",
        "plt.imshow(dst)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suKB5fNPe5NN"
      },
      "source": [
        "# 7. ÏòÅÏÉÅ ÎßàÏä§ÌÇπ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w8mNT1We7xY"
      },
      "source": [
        "## 7.1 ÏÇ∞Ïà† Ïó∞ÏÇ∞(Î∫ÑÏÖà)ÏùÑ ÏÇ¨Ïö©Ìïú ÎßàÏä§ÌÇπ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEAvou2veZ8D"
      },
      "outputs": [],
      "source": [
        "image1 = cv2.imread(IMG_DIR+'chest_01.png',cv2.IMREAD_GRAYSCALE)\n",
        "image2 = cv2.imread(IMG_DIR+'square_mask.png',cv2.IMREAD_GRAYSCALE)\n",
        "print(image2.shape, image2[0][0])\n",
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Original\")\n",
        "plt.imshow(image1, cmap='gray', vmin=0, vmax=255)\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"mask\")\n",
        "plt.imshow(image2, cmap='gray', vmin=0, vmax=255)\n",
        "\n",
        "dst =\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"Result\")\n",
        "plt.imshow(dst, cmap='gray', vmin=0, vmax=255)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP5FnS0rfZAq"
      },
      "source": [
        "## 7.2 ÎÖºÎ¶¨Ïó∞ÏÇ∞ÏùÑ Ïù¥Ïö©Ìïú ÎßàÏä§ÌÇπ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XStYAmFZpGrr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukq_W6gBf1_i"
      },
      "source": [
        "# 8. Ben Graham's preprocessing method\n",
        "#### APTOS 2019 Blindness Detection Í≤ΩÏüÅÎ∂ÄÎ∂Ñ Ïö∞ÏäπÏûê Ben GrahamÏùò Ï†ÑÏ≤òÎ¶¨ Î∞©Î≤ï\n",
        "- https://www.kaggle.com/competitions/aptos2019-blindness-detection\n",
        "- https://www.kaggle.com/code/habibmrad1983/aptos-eye-preprocessing-in-diabetic-retinopathy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QKqzSLbgFkR"
      },
      "outputs": [],
      "source": [
        "img = np.array([[0, 0, 0, 0, 0],\n",
        "                [0, 9, 9, 9, 0],\n",
        "                [0, 9, 9, 9, 0],\n",
        "                [0, 9, 9, 9, 9],\n",
        "                [0, 0, 0, 0, 0]])\n",
        "mask =\n",
        "\n",
        "grid =\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmIRx9EEgE1c"
      },
      "outputs": [],
      "source": [
        "def crop_image(img, tol=7):\n",
        "    gray_img =\n",
        "    mask =\n",
        "    grid =\n",
        "\n",
        "    check_shape =\n",
        "    if (check_shape == 0): # image is too dark so that we crop out everything,\n",
        "        return img # return original image\n",
        "    else:\n",
        "        img1=img[:,:,0][grid]\n",
        "        img2=img[:,:,1][grid]\n",
        "        img3=img[:,:,2][grid]\n",
        "        img =\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4csFbDOoflsH"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE=224\n",
        "\n",
        "def load_ben_color(path, tol=7, sigmaX=10):\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = crop_image(image, tol)\n",
        "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image=cv2.addWeighted ( image, 4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPZXVa0egTGM"
      },
      "outputs": [],
      "source": [
        "path= IMG_DIR+'678_left.png'\n",
        "\n",
        "src = cv2.imread(path)\n",
        "src = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "dst =\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.subplot(2,3,1);plt.title('Original');plt.imshow(src)\n",
        "plt.subplot(2,3,2);plt.title('Transformed');plt.imshow(dst)\n",
        "plt.subplot(2,3,4);\n",
        "hist = cv2.calcHist(dst, [0], None, [256], [0,256])\n",
        "plt.title('Histogram: R')\n",
        "plt.bar(range(len(hist)), hist.flatten())\n",
        "\n",
        "plt.subplot(2,3,5);plt.title('Histogram: G')\n",
        "hist = cv2.calcHist(dst, [1], None, [256], [0,256])\n",
        "plt.bar(range(len(hist)), hist.flatten())\n",
        "\n",
        "plt.subplot(2,3,6);plt.title('Histogram: B')\n",
        "hist = cv2.calcHist(dst, [2], None, [256], [0,256])\n",
        "plt.bar(range(len(hist)), hist.flatten())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjVqJXv1XcrT"
      },
      "source": [
        "## 9. ÌäπÏÑ± Ï∂îÏ∂ú HOG (Histogram of Orient Gradients)\n",
        "- ÏΩîÎìú Ï∂úÏ≤ò: https://jakevdp.github.io/PythonDataScienceHandbook/05.14-image-features.html\n",
        "- https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=tommybee&logNo=221173056260"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fF4vKfUDTLWA"
      },
      "outputs": [],
      "source": [
        "from skimage import data, color, feature\n",
        "\n",
        "image = data.chelsea()\n",
        "image = color.rgb2gray(data.chelsea())\n",
        "#image = cv2.imread(IMG_DIR+'lena.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "hog_vec, hog_image = feature.hog(image, visualize=True)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6),\n",
        "                      subplot_kw = dict(xticks=[], yticks=[]))\n",
        "ax[0].imshow(image, cmap='gray')\n",
        "ax[0].set_title('input image')\n",
        "\n",
        "ax[1].imshow(hog_image, cmap='Grays')\n",
        "ax[1].set_title('Visualization of HOG features')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VokWyULZhdqz"
      },
      "source": [
        "# 10. ÏòÅÏÉÅÏù¥ÏßÑÌôî: Thresholding, Binarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5Yvfm2cij1V"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(IMG_DIR+'678_left.png',cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Original: Gray\")\n",
        "plt.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "# It's good practice to blur images as it removes noise\n",
        "image = cv2.GaussianBlur(image, (3, 3), 0)\n",
        "\n",
        "# Using adaptiveThreshold\n",
        "th1 = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                               cv2.THRESH_BINARY, 3, 5)  # C: 1, 2, 3, 4, 5\n",
        "plt.title(\"Adaptive Mean Thresholding\")\n",
        "plt.imshow(th1, cmap='gray', vmin=0, vmax=255)\n",
        "\n",
        "th2 = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                               cv2.THRESH_BINARY, 3, 5) # C: 1, 2,3, 4, 5\n",
        "plt.subplot(1,3,3)\n",
        "plt.title(\"Adaptive Gaussian Thresholding\")\n",
        "plt.imshow(th2, cmap='gray', vmin=0, vmax=255)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ifnDqHhi5zd"
      },
      "source": [
        "# 10. Ïú§Í≥ΩÏÑ†(contour) Ï∂îÏ∂ú"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpX-thwlWXV0"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(IMG_DIR+'right04.jpg',cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "th, binary = cv2.threshold(image,  )\n",
        "\n",
        "contours, hierarchy = cv2.findContours(binary,  )\n",
        "src = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "n_contours = len(contours)\n",
        "\n",
        "for i in range(n_contours):\n",
        "    cv2.drawContours(src, [contours[i]], 0, (0, 0, 255), 2)\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.subplot(1, 2, 1);plt.title(\"Original\");plt.imshow(image, cmap='gray')\n",
        "plt.subplot(1, 2, 2);plt.title(\"Result\");plt.imshow(src)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDTEjImkrod-"
      },
      "source": [
        "# 11. ÌÖúÌîåÎ¶ø Îß§Ïπ≠"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPa1WBolqlUk"
      },
      "outputs": [],
      "source": [
        "# ÏòÅÏÉÅÏóêÏÑú ÌÖúÌîåÎ¶ø ÏòÅÏÉÅÍ≥ºÏùºÏπòÌïòÎäî Í≥≥ Ï∞æÍ∏∞\n",
        "src = cv2.imread(IMG_DIR +'chest_05.png', cv2.IMREAD_GRAYSCALE)\n",
        "templ = cv2.imread(IMG_DIR+'chest_template.png', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# ÌÉ¨ÌîåÎ¶ø Îß§Ïπ≠ & Í≤∞Í≥º Î∂ÑÏÑù\n",
        "res = cv2.matchTemplate(src, templ,  )\n",
        "\n",
        "# ÏµúÏÜüÍ∞í 0, ÏµúÎåìÍ∞í 255 ÏßÄÏ†ïÌïòÏó¨ Í≤∞Í≥ºÍ∞íÏùÑ Í∑∏Î†àÏù¥Ïä§ÏºÄÏùº ÏòÅÏÉÅÏúºÎ°ú ÎßåÎì§Í∏∞\n",
        "res_norm = cv2.normalize(res, )\n",
        "\n",
        "# ÏµúÎåìÍ∞íÏùÑ Ï∞æÏïÑÏïºÌïòÎØÄÎ°ú minmaxloc ÏÇ¨Ïö©,  max, minÏ¢åÌëú, maxÏ¢åÌëú Î∞òÌôò\n",
        "_, maxv, _, maxloc = cv2.minMaxLoc(res)\n",
        "\n",
        "# Îß§Ïπ≠ Í≤∞Í≥ºÎ•º Îπ®Í∞ÑÏÉâ ÏÇ¨Í∞ÅÌòïÏúºÎ°ú ÌëúÏãú\n",
        "th, tw = templ.shape[:2]\n",
        "dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)\n",
        "cv2.rectangle(dst, maxloc, (maxloc[0] + tw, maxloc[1] + th), (255, 0, 0), 2)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 2, 1);plt.title(\"Result\");plt.imshow(dst)\n",
        "plt.subplot(2, 2, 2);plt.title(\"Original\");plt.imshow(src, cmap='gray')\n",
        "plt.subplot(2, 2, 3);plt.title(\"Template\");plt.imshow(templ, cmap='gray')\n",
        "plt.subplot(2, 2, 4);plt.title(\"res_norm\");plt.imshow(res_norm, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI2vLXc1r81t"
      },
      "outputs": [],
      "source": [
        "# ÌÖúÌîåÎ¶øÏù¥ ÌöåÏ†ÑÎêú ÌòïÌÉúÎ°ú ÏûàÎäî Í≤ΩÏö∞Ïóê Ï∞æÏùÑ Ïàò ÏûàÎäîÍ∞Ä?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxn6oepesBha"
      },
      "outputs": [],
      "source": [
        "# ÌÖúÌîåÎ¶øÏùò ÌÅ¨Í∏∞Í∞Ä ÏûëÏùÄ Í≤ΩÏö∞ÏóêÎèÑ Ï∞æÏùÑ Ïàò ÏûàÎäîÍ∞Ä?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpKKz35ZqcpL"
      },
      "source": [
        "# ÏñºÍµ¥ Ïù∏Ïãù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n54-F84BKe5"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/TUIlmenauAMS/Videocoding/raw/main/seminars/videos/videorec.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSs7YwhmBQum"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from skimage.transform import resize\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4J3Z1LsBUEH"
      },
      "outputs": [],
      "source": [
        "# Í∞ÄÏ§ëÏπò ÌååÏùº Í≤ΩÎ°ú\n",
        "cascade_filename =IMG_DIR+'/haarcascade_frontalface_alt.xml'\n",
        "# Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
        "cascade = cv2.CascadeClassifier(cascade_filename)\n",
        "\n",
        "if not cascade:\n",
        "    print('no cascade file')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C0rz6p2BXqy"
      },
      "outputs": [],
      "source": [
        "def display_video(video):\n",
        "    fig = plt.figure(figsize=(3,3))  #Display size specification\n",
        "\n",
        "    mov = []\n",
        "    for img in video:  #Append videos one by one to mov\n",
        "        # Í∑∏Î†àÏù¥ Ïä§ÏºÄÏùº Î≥ÄÌôò\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # cascade ÏñºÍµ¥ ÌÉêÏßÄ ÏïåÍ≥†Î¶¨Ï¶ò\n",
        "        results = cascade.detectMultiScale(gray,            # ÏûÖÎ†• Ïù¥ÎØ∏ÏßÄ\n",
        "                                            scaleFactor= 1.1,# Ïù¥ÎØ∏ÏßÄ ÌîºÎùºÎØ∏Îìú Ïä§ÏºÄÏùº factor\n",
        "                                            minNeighbors=5,  # Ïù∏Ï†ë Í∞ùÏ≤¥ ÏµúÏÜå Í±∞Î¶¨ ÌîΩÏÖÄ\n",
        "                                            minSize=(20,20)  # ÌÉêÏßÄ Í∞ùÏ≤¥ ÏµúÏÜå ÌÅ¨Í∏∞\n",
        "                                            )\n",
        "        for box in results:\n",
        "            x, y, w, h = box\n",
        "            cv2.rectangle(img, (x,y), (x+w, y+h), (255,255,255), thickness=2)\n",
        "        img = plt.imshow(img, animated=True)\n",
        "        plt.axis('off')\n",
        "        mov.append([img])\n",
        "\n",
        "    #Animation creation\n",
        "    anime = animation.ArtistAnimation(fig, mov, interval=50, repeat_delay=20)\n",
        "\n",
        "    plt.close()\n",
        "    return anime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAk5QckbBalj"
      },
      "outputs": [],
      "source": [
        "video = imageio.mimread(IMG_DIR+'videorec.mp4')  #Loading video\n",
        "HTML(display_video(video).to_html5_video())  #Inline video display in HTML5"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ai_lecture",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
